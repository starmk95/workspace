{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ud3D8UDcqVzZ"
   },
   "source": [
    "## [실습] HuggingFace에서 공개 모델 사용하기\n",
    "\n",
    "http://huggingface.co 의 링크에서 공개된 모델을 사용하는 방법을 알아보겠습니다.   \n",
    "큰 모델은 양자화를 통해 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xlqtVm8sqVzb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.29.1)\n",
      "Requirement already satisfied: trl in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.45.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: safetensors in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: rich in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install peft accelerate datasets huggingface_hub trl transformers bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DD0UMstIy8xK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.41)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-huggingface) (0.29.1)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-huggingface) (3.4.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-huggingface) (0.21.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-huggingface) (4.49.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qs1xKT2qVzb"
   },
   "source": [
    "허깅페이스 모델에 접속하기 위해, 허깅페이스 라이브러리를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "izDffqYdqVzb"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token='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') # API 키를 입력합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5PJPKa7y8xM"
   },
   "source": [
    "모델과 토크나이저를 불러옵니다.   \n",
    "토크나이저는 모델의 구동에 필수적이며, 모델별 Special Token이나 Chat Template 등의 요소가 포함되어 있습니다.    \n",
    "따라서 모델을 저장할 때는 토크나이저도 항상 같이 저장해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6Ytk4zI31Ibd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar  5 14:56:13 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 538.78                 Driver Version: 538.78       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX330         WDDM  | 00000000:2D:00.0 Off |                  N/A |\n",
      "| N/A   48C    P0              N/A / ERR! |      0MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "duT7dY57y8xM"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CYJ-wzljy8xM"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot access accelerator device when none is available.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# huggingface.co/ 뒤에 붙는 주소와 동일합니다.\u001b[39;00m\n\u001b[32m     14\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_id)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 가중치의 데이터타입 자동 감지\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# quantization_config=quantization_config,\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 양자화란? 큰 모델의 가중치를 작게 만드는 방법\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 32비트 모델은 *4, 16비트 모델은 *2를 하여 가용 파라미터 확인\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 이미 양자화된 모델을 불러올 때는\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# config.json에 양자화 옵션이 들어가기 때문에\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# quantization_config을 안 넣어도 됨\u001b[39;49;00m\n\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 0번 GPU에 할당\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# 한번 불러온 모델은 .cache에 저장되어 이후 바로 불러올 수 있음\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    563\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    568\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    570\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:262\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    260\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    264\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:4319\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4310\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4312\u001b[39m     (\n\u001b[32m   4313\u001b[39m         model,\n\u001b[32m   4314\u001b[39m         missing_keys,\n\u001b[32m   4315\u001b[39m         unexpected_keys,\n\u001b[32m   4316\u001b[39m         mismatched_keys,\n\u001b[32m   4317\u001b[39m         offload_index,\n\u001b[32m   4318\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4319\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[32m   4323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4326\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4327\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4330\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4331\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4339\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   4340\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:4897\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path, weights_only)\u001b[39m\n\u001b[32m   4895\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4896\u001b[39m         fixed_state_dict = \u001b[38;5;28mcls\u001b[39m._fix_state_dict_keys_on_load(state_dict)\n\u001b[32m-> \u001b[39m\u001b[32m4897\u001b[39m         new_error_msgs, offload_index, state_dict_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4898\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4899\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfixed_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4900\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4902\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4913\u001b[39m         error_msgs += new_error_msgs\n\u001b[32m   4914\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4915\u001b[39m     \u001b[38;5;66;03m# Sharded checkpoint or whole but low_cpu_mem_usage==True\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:896\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys, pretrained_model_name_or_path)\u001b[39m\n\u001b[32m    893\u001b[39m         param_device = \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    895\u001b[39m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    898\u001b[39m     hf_quantizer.create_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\modeling.py:304\u001b[39m, in \u001b[36mset_module_tensor_to_device\u001b[39m\u001b[34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[39m\n\u001b[32m    297\u001b[39m device_quantization = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    299\u001b[39m     \u001b[38;5;66;03m# leave it on cpu first before moving them to cuda\u001b[39;00m\n\u001b[32m    300\u001b[39m     \u001b[38;5;66;03m# # fix the case where the device is meta, we don't want to put it on cpu because there is no data =0\u001b[39;00m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    302\u001b[39m         param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    303\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m param.device.type != \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m.type == \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    305\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m param_cls.\u001b[34m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mInt8Params\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mFP4Params\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mParams4bit\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    306\u001b[39m     ):\n\u001b[32m    307\u001b[39m         device_quantization = device\n\u001b[32m    308\u001b[39m         device = \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: Cannot access accelerator device when none is available."
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "\n",
    "# 모델의 주소를 입력합니다.\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\" # 각 모델들을 순서대로 각각 불러와서 설치\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B\"\n",
    "# model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "model_id = \"meta-llama/Llama-3.2-1B-instruct\"\n",
    "\n",
    "# huggingface.co/ 뒤에 붙는 주소와 동일합니다.\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "\n",
    "    torch_dtype='auto', # 가중치의 데이터타입 자동 감지\n",
    "\n",
    "    # quantization_config=quantization_config,\n",
    "    # 양자화란? 큰 모델의 가중치를 작게 만드는 방법\n",
    "\n",
    "    # 32비트 모델은 *4, 16비트 모델은 *2를 하여 가용 파라미터 확인\n",
    "\n",
    "    # 이미 양자화된 모델을 불러올 때는\n",
    "    # config.json에 양자화 옵션이 들어가기 때문에\n",
    "    # quantization_config을 안 넣어도 됨\n",
    "\n",
    "    device_map={\"\":0}) # 0번 GPU에 할당\n",
    "\n",
    "# 한번 불러온 모델은 .cache에 저장되어 이후 바로 불러올 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoveYzx2LJlN"
   },
   "source": [
    "모델의 구조는 아래와 같이 확인 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "89eXkzYgLJlO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "H0yG2H2W2cSd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33mllama_test\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"llama_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4PORzZBL3Uer"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llma_test\\\\tokenizer_config.json',\n",
       " 'llma_test\\\\special_tokens_map.json',\n",
       " 'llma_test\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"llma_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke0qA6jUy8xM"
   },
   "source": [
    "모델의 Generation을 잘 수행하기 위해, *text-generation* pipeline을 사용합니다.    \n",
    "기존의 모델에 들어가던 매개변수(max_new_tokens 등)은 여기에서 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sZQPv0-oy8xM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 아래 옵션은 주로 모델 페이지의 generate_config에서 참고할 수 있습니다.\u001b[39;00m\n\u001b[32m      2\u001b[39m gen_config = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m      3\u001b[39m     do_sample=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# do_sample : 확률 샘플링의 영부 (False: Greedy)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# Top 20안에서만 샘플링 --> P와 K 교집합으로 처리됨\u001b[39;00m\n\u001b[32m     13\u001b[39m )\n\u001b[32m     16\u001b[39m pipe = pipeline(\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     model=\u001b[43mmodel\u001b[49m,\n\u001b[32m     19\u001b[39m     tokenizer=tokenizer,\n\u001b[32m     20\u001b[39m     return_full_text=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     21\u001b[39m     **gen_config\n\u001b[32m     22\u001b[39m     )\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# return_full_text : 프롬프트를 포함하여 출력할 것인지 결정 (Default : True)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 아래 옵션은 주로 모델 페이지의 generate_config에서 참고할 수 있습니다.\n",
    "gen_config = dict(\n",
    "    do_sample=True,\n",
    "    # do_sample : 확률 샘플링의 영부 (False: Greedy)\n",
    "    max_new_tokens=512,\n",
    "    repetition_penalty = 1.1,\n",
    "    # 동일 토큰 반복 방지 패널티\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.8,\n",
    "    # 확률 상위 80% 안에서만 샘플링\n",
    "    top_k = 20\n",
    "    # Top 20안에서만 샘플링 --> P와 K 교집합으로 처리됨\n",
    ")\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    **gen_config\n",
    "    )\n",
    "# return_full_text : 프롬프트를 포함하여 출력할 것인지 결정 (Default : True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgma8M-1y8xN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '?\\n거대 언어 모델 (Giant Language Model)란 단어, 문장을 조작하여 새로운 문장, 단어, 또는 문구를 생성하는 텍스트生成체입니다. \\n어떤 개념이나 문장을 조작하여 새로운 문장을 만들기 위한 목적에 따라 여러 개의 텍스트 Generation Model을 사용할 수 있습니다.\\n\\n1. **Text Generation Model**: 단어, 문장을 조작하여 새로운 문장을 생성하는 Model. 이 Model은 일반적으로 Text-to-Speech (TTS) 및 Text Summarization (TS) 같은 용도로 사용됩니다.\\n2. **Language Model**: 단어나 문장을 조작하여 새로운 문장을 생성하는 Model. 이 Model은 일반적으로 Language Translation (LT), Language Understanding (LU), Language Generation (LG) 같은 용도로 사용됩니다.\\n3. **Generative Adversarial Network (GAN)**: Text Generation Model과 Language Model의 연합으로, GAN은 새로운 문장을 생성하기 위해 텍스트와 문장을 조작합니다.\\n4. **Neural Network-based Models**: Text Generation Model과 Language Model의 연합으로, Neural Network-based Models은 다양한 용도로 사용됩니다.\\n\\n거대 언어 모델은 다음과 같은 특징을 가지고 있습니다.\\n\\n* **대형 언어 모델**: 거대 언어 모델은 대규모의 데이터セット을 사용하여 학습하고, 이는 큰 텍스트 생성 capability을 제공합니다.\\n* **AI 및 Machine Learning**: 거대 언어 모델은 AI 및Machine Learning에 의해 개발되고, 이러한 기술을 사용하여 더 많은 텍스트를 생성할 수 있습니다.\\n* **Flexibility**: 거대 언어 모델은 다양한 용도로 사용될 수 있으며, 다른 용도에서 더 적합한 model을 사용할 수 있습니다.\\n* **Efficiency**: 거대 언어 모델은 효율적인 텍스트 생성 방법을 제공하며, 이를 통해 더 많은 text를 생성할 수 있습니다.\\n\\n거대 언어 모델은 다양한 용도로 사용될 수 있으며, 이 용도의 특정 detail은 각 용도로 사용되는 model의 특징을 다루고 있습니다.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"거대 언어 모델이 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMfVjJKEy8xN"
   },
   "source": [
    "pipe에 바로 텍스트를 입력해도 되지만,   \n",
    "랭체인과의 연동을 위해 `langchain_huggingface` 모듈을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8ppFbDzy8xN"
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe, pipeline_kwargs=gen_config)\n",
    "# Instruct 모델이 아닌 경우\n",
    "\n",
    "chat_model = ChatHuggingFace(llm=llm, tokenizer=tokenizer)\n",
    "# Instruct 모델인 경우, tokenizer의 chat template 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Il4cc5E4qVzc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 1964년 7월 5일 태어난 그는 미국의 전 공화국 시대 소설가이자 작가로 유명한 아메리칸 인물입니다.\\n\\n이브러햄 링컨은 1950년대 후반에 미국에서 일하는 동안, 1952년 11월에 이집트에서 세워진 미국의 첫 번째 우주선인 스타리움 1을 지휘하면서 우주 여행을 시작했습니다. 그는 또한 1953년 9월에 우주 여행을 통해 뉴욕시와 런던시를 방문했습니다. 1960년 10월에는 미국의 첫 번째 우주선인 스톤 1을 지휘하여 1961년 8월 12일에는 그라운드에서 이집트로의 우주선이 도착했습니다. 1966년 11월에 그는 이집트를 떠나 1967년 1월에 미국으로 돌아온 후 14일만에 사망했다. \\n\\n이브러햄 링컨은 1968년 12월 24일부터 1972년 2월 28일까지 미국의 40대에 belonged을 것으로 간주되었습니다. 1972년 3월 20일부터 1980년 11월 27일까지 그는 50대에 belonged을 것으로 간주되었습니다. 1990년 10월 16일부터 2000년 12월 31일까지 그는 60대에 belonged을 것으로 간주되었습니다. 2003년 11월 29일부터 2010년 10월 18일까지 그는 70대에 belonged을 것으로 간주되었습니다. 2010년 10월 19일부터 2020년 11월 13일까지 그는 80대에 belonged을 것으로 간주되었습니다. 2020년 11월 14일부터 2022년 1월 23일까지 그는 90대에 belonged을 것으로 간주되었습니다. 2022년 1월 24일부터 2023년 1월 26일까지 그는 100대에 belong되었습니다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instruct 모델에서는 포맷을 지키지 않으면 제대로 된 결과가 나오지 않음\n",
    "llm.invoke(\"에이브러햄 링컨이 누구야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlUltfHEmfB6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='에이브러햄 링컨 (Ebenezer Scrooge, 1812-1871)은 잉글랜드의 시인, 작가이자 시인이자 주도적인 개혁가였습니다. 그는 \"A Christmas Carol\"라는 책을 출판한 것으로 가장 잘 알려져 있습니다.\\n\\n그는 1843년 12월 21日に 런던에서 태어난 그는 1850년 8월 7일에 사망했습니다.', additional_kwargs={}, response_metadata={}, id='run-4c4bf532-ad3a-44fe-8ad6-7373df69651c-0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer에 저장된 Template 을 기반으로, 질문 답변을 생성\n",
    "chat_model.invoke(\"에이브러햄 링컨이 누구야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCqtk5bdmf1X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"?\\nAbraham Lincoln was the 16th President of the United States, serving from March 4, 1861 until his assassination in April 1865. He is widely regarded as one of the greatest leaders in American history.\\nLincoln was born on February 12, 1809, in a log cabin in Kentucky to Thomas and Nancy Lincoln. His early life was marked by poverty and hard work, but he eventually became a successful lawyer and politician. In 1842, he married Mary Todd, with whom he had four children.\\n\\nDuring the Civil War, Lincoln faced many challenges, including secessionist states, abolitionists, and slavery. As president, he issued the Emancipation Proclamation in 1863, which declared all slaves in Confederate territory to be free. However, it was not until the passage of the 13th Amendment to the Constitution in 1865 that slavery was officially abolished.\\n\\nLincoln's leadership during the war led to several key victories, including the Battle of Gettysburg, where he delivered his famous Gettysburg Address. The speech outlined the principles of equality and liberty upon which the United States was founded.\\n\\nAfter the war, Lincoln continued to lead the country through its Reconstruction era, working to rebuild the South and establish civil rights for African Americans. He also oversaw the Homestead Act, which allowed settlers to claim land in the West.\\n\\nLincoln's legacy has endured long after his death. He is remembered as a strong leader who guided the nation through its darkest hour, and his commitment to freedom and equality continues to inspire people around the world.\\n\\nHere are some interesting facts about Abraham Lincoln:\\n\\n* He was the first Republican to be elected President.\\n* He was a skilled writer and published articles under a pseudonym.\\n* He was known for his tall stature (6 feet 4 inches) and his love of books.\\n* He was a strong supporter of education and advocated for higher education for women.\\n* He believed in the importance of unity and reconciliation, and worked to heal the divisions between the North and South.\\n\\nOverall, Abraham Lincoln is remembered as one of the most important figures in American history, and his legacy continues to shape our country today.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who is Abraham Lincoln?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1Y_DCFdbsqa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Abraham Lincoln was the 16th President of the United States, serving from 1861 until his assassination in 1865. He is widely regarded as one of the most influential leaders in American history.\\n\\nLincoln was born on February 12, 1809, in a log cabin in Kentucky to Thomas and Nancy Lincoln. He grew up in poverty and had very little formal education, but he was an avid reader and developed a strong interest in law and politics. He studied law in Springfield, Illinois, where he became a licensed attorney at age 21.\\n\\nIn 1832, Lincoln married Mary Todd, and they had four children together. During the Mexican-American War (1846-1848), Lincoln served in the Illinois state legislature and later as a member of the U.S. House of Representatives. In 1858, he ran for the U.S. Senate against Stephen Douglas, a prominent Democrat, and won, becoming a national figure due to his strong oratory skills.\\n\\nThe election of 1860 sparked controversy when several Southern states seceded from the Union, fearing that Lincoln's victory would lead to abolition of slavery. The Kansas-Nebraska Act of 1854 allowed new states to decide whether to allow slavery, leading to pro-slavery and anti-slavery violence in the Kansas territory.\\n\\nIn response, Lincoln issued the Emancipation Proclamation in 1863, declaring all slaves in Confederate territory to be free. He also oversaw the passage of the 13th Amendment to the Constitution, which abolished slavery throughout the United States.\\n\\nDuring the Civil War, Lincoln led the Union Army to victory, and in 1865, he delivered the Gettysburg Address, a speech that redefined the purpose of the war and honored the fallen soldiers. On April 14, 1865, Lincoln was assassinated by John Wilkes Booth while attending a play at Ford's Theatre in Washington, D.C.\\n\\nAfter his death, Vice President Andrew Johnson succeeded him as president, but his term was short-lived. Lincoln's legacy has endured, and he is remembered as a champion of freedom, equality, and unity. His leadership during the Civil War and his commitment to preserving the Union have made him one of the most revered figures in American history.\\n\\nSome interesting facts about Abraham Lincoln:\\n\\n* He was a skilled mechanic and inventor, and designed and built his own printing press.\\n* He was a passionate advocate for education and believed in the importance of reading and learning.\\n* He was a strong supporter of the abolitionist\", additional_kwargs={}, response_metadata={}, id='run-0ed8332b-29ff-405d-9eed-531f6ac701c5-0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"Who is Abraham Lincoln?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2NaJy1LqVzc"
   },
   "source": [
    "불러온 모델의 종류에 따라, 토크나이저에서 Special Tokens와 Chat Template를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MRsvLUjnqVzc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>', '<|eot_id|>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wj67Abt5MBn-"
   },
   "outputs": [],
   "source": [
    "tokenizer.eos_token, tokenizer.bos_token, tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oG0Hij3qVzc"
   },
   "outputs": [],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQvo6YWKbz39"
   },
   "source": [
    "OpenAI에서 배웠던 포맷의 메시지는    \n",
    "토크나이저를 통해 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7i325dQnqVzc"
   },
   "outputs": [],
   "source": [
    "chat = [\n",
    "    { \"role\": \"user\", \"content\": \"한국 프로야구 리그인 KBO에 대해 설명해 주세요.\" },\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(chat,\n",
    "                                       tokenize=False,\n",
    "                                       add_generation_prompt= True) #False)\n",
    "\n",
    "# add_generation_prompt : 입력 텍스트 뒤에 generation prompt를 추가할지 여부\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcUrYR1Vb_7K"
   },
   "source": [
    "채팅 모델에서는 아래와 같이 토크나이저를 연결해야 하나,    \n",
    "ChatHuggingFace에서는 그대로 실행해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2vUcAghqVzd"
   },
   "outputs": [],
   "source": [
    "summarize_instruction ='''아래의 글을 읽고, 200자 이내의 요약문을 작성하세요.'''\n",
    "\n",
    "example_news='''LG 트윈스가 6월 14일부터 16일까지 잠실야구장에서 열리는 롯데 자이언츠와 주말 홈 3연전에서 승리 기원 시구 및 '잔망루피 데이'를 진행한다.\n",
    "\n",
    "먼저 14일에는 '피지컬: 100 시즌2'에 출연한 전 핸드볼 선수 박하얀이 시구, 프로그램 우승자 아모띠가 시타를 각각 진행한다. 두 사람은 \"선수들 모두 다치지 않고, 좋은 경기를 펼치면 좋겠다. LG 트윈스가 좋은 성적을 거둘 수 있도록 끝까지 열심히 응원하겠다\"고 소감을 전했다. 이날 경기 전에는 박해민 선수의 개인 통산 1500안타와 2000루타 달성을 기념하는 KBO 시상식도 열릴 예정이다.\n",
    "\n",
    "이어 15일에는 이건태 소방관의 시구와 농심 '배홍동' 마스코트의 시타가 있다. 이건태 소방관은 구조대원으로서 화재 진압 및 여러 구조 현장에서 활동하고 있다. 특히 수중 수색 기술을 개발, 교육하는 등 대한민국 구조 활동에 중요한 역할을 하고 있다. 이날 경기 전에는 신민재, 문성주의 팬 사인회와 김현수의 개인 통산 2000경기 출장 달성을 기념하는 KBO 시상식이 진행된다.\n",
    "\n",
    "\n",
    "아이돌그룹 '더보이즈'의 멤버 현재. /사진=LG 트윈스 제공\n",
    "끝으로 16일에는 아이돌그룹 '더보이즈'의 멤버 현재가 승리 기원 시구를 진행한다. '더보이즈'는 오는 7월 월드투어를 통해 팬들을 만날 예정이다. 최근 두 번째 정규 앨범인 '판타지(PHANTASY)' Pt.3 '러브레터(Love Letter)'를 발매하고, 음원과 음반, 글로벌 차트 등에서 큰 성과를 거두고 있다. 현재는 \"데뷔 후 첫 시구 도전이라 떨리는 마음도 있지만 설레는 마음이 더 크다. 자신 있게 시구하고, 선수들이 좋은 경기 펼칠 수 있도록 열심히 응원하겠다\"고 전했다.\n",
    "\n",
    "아울러 LG 트윈스는 '잔망루피 데이'를 맞아 '잔망루피' 스페셜 티켓과 내야 광장 포토존을 운영하고, 2024시즌 '잔망루피' 콜라보 신상품을 출시한다. 출시 상품은 유니폼, 마킹 키트, 모자, 봉제 인형과 키링, 응원 타월, 부채, 부적 키링 3종과 마그넷 세트 등이며, 이를 기념해 10% 할인 프로모션을 진행한다. '잔망루피'는 지난 2021년 LG트윈스의 신입 응원단원으로 합류했으며, 다양한 협업 활동을 통해 팬들의 사랑을 받고 있다.\n",
    "\n",
    "한편 이번 주말 홈 3연전 포토 카드의 주인공은 오지환과 '잔망루피'다. LG 트윈스 홈 경기 이벤트 진행에 대한 자세한 내용은 LG트윈스 홈페이지와 모바일앱, SNS 계정을 통해 확인할 수 있다.\n",
    "'''\n",
    "\n",
    "prompt = [\n",
    "    {'role':'system','content':summarize_instruction},\n",
    "    {'role':'user','content':f'Context: {example_news}'}]\n",
    "\n",
    "llm.invoke(tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HLmP0Slzcyxb"
   },
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    {'role':'system','content':'''당신은 전문적인 QA 봇입니다.\n",
    "아래의 Context와 질문을 읽고, 이에 대한 답변을 작성하세요.\n",
    "Context에서 확인할 수 있는 내용만을 사용하여 답변하고, 답변을 지어내지 마세요.'''},\n",
    "    {'role':'user','content':f'''\n",
    "Context={example_news}\n",
    "\n",
    "질문: 왜 잔망루피가 LG 트윈스 포토카드에 있어?\n",
    "\n",
    "답변:'''}]\n",
    "\n",
    "print(llm.invoke(tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQ8RLRZrcdgP"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', '{instruction}'),\n",
    "        ('user', '{context}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_chain = chat_template | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjS-Jn5ey8xP"
   },
   "outputs": [],
   "source": [
    "print(llm_chain.invoke({'instruction':summarize_instruction, 'context':example_news}))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
